---
layout: post
title: flink的基本概念理解
categories: flink
description: flink basic concepts
keywords: flink, concepts, 基本概念
---

### flink的基本概念理解

![flink编程api和dataflow视图](/images/flink/basic_concepts/flink-concepts_program-dataflow.png)

上图从 `编程api` 和 `逻辑数据流图` 这两个角度静态展示了的flink的最基本概念。
* 从 `编程api` 的角度看，flink 的 job 基本组成元素包括：
作为 job 输入的 source、对 stream 进行操作的 transformation 和 job 输出的 sink（每一部分都可以是多个）。
* 从 `逻辑数据流图` 的角度看，source/transformation/sink 都是operator，operator之间流动的是stream。逻辑数据流由operators和stream构成。

**transformations是programs层面的概念，operators是dataflow层面的概念。通常programs层面的transformations和dataflow层面的operators一一对应，
也有一些情况一个transformation对应多个operators。**

从`逻辑数据流图`的角度进一步可以看到`并行视图下的逻辑数据流图`如下：
![flink编程api和dataflow视图](/images/flink/basic_concepts/parallel_dataflows.png)
上图中， stream 被分割成 `stream partition` ，operator 被分割成 `operator subtask` 。
相关概念：
* operator的 `parallelism`（并行度）：该operator对应的subtask个数
* operator的 `parallelism`（并行度）：产生该stream的operator的并行度
上面的并行视图中，source/map/keyBy/window/apply operator的并行度都是2，sink operator的并行度是1。

（注意，这里特意强调并行度是指operator的并行度，在上图中还没有task的概念）

上图还展示了 stream 在 operator 之间流动的2种模式：
* one-to-one（forwarding）：stream 维护着分区和元素的顺序
* redistributing：stream 的分区会改变，比如 keyBy（基于hash值重新分区），broadcast(广播)或者 rebalance（随机分发）


![flink编程api和dataflow视图](/images/flink/basic_concepts/flink-concepts_tasks-chains.png)

flink会


ref: 
[Introduction to Apache Flink](https://flink.apache.org/introduction.html#)
[Dataflow Programming Model]https://ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/programming-model.html
[Flink中的一些核心概念](http://blog.csdn.net/yanghua_kobe/article/details/51298871)


StreamExecutionEnvironment#getExecutionPlan 实际展示的是StreamGraph的plan json。

概念的命名变化：
TODO


理解： sourceTransformation/sinkTransformation都继承自StreamTransformation，只是前者额外多了operator（StreamSource<T, ?>类型的）属性，后者额外多了input,operator（StreamSink类型的）,stateKeySelector。
OneInputTransformation同样继承自StreamTransformation，有input，operator（OneInputStreamOperator<IN, OUT>类型的）属性。

也就是说：是xxxTransformation里包含了对应的各式StreamOperator，一般来说，A类型的Transformation会对应A类型的StreamOperator，
比如：sourceTransformation包含对应的是StreamSource的StreamOperator，sinkTransofmation包含对应的是 StreamSink类型的StreamOperator，
OneInputTransformation->OneInputStreamOperator的。不过有些xxxTransformation里没有实际对应的StreamOperator，
比如：SplitTransformation/UnionTransformation，表示是逻辑概念。PartitionTransformation这个逻辑的有StreamPartitioner<T> partitioner这个成员 (StreamPartitioner实现ChannelSelector接口)。

StreamSource 和 StreamSink 都是 StreamOperator。
此外需要注意到，StreamSource/StreamSink都继承自AbstractUdfStreamOperator，该父类有一个泛型成员变量userFunction表示用户function。
userFunction的典型继承体系：RichFlatMapFunction -> AbstractRichFunction -> FlatMapFunction -> Function。


从JSONGenerator#decorateNode方法中可以看到，在把streamNode转换为Json的时候，type字段和content字段放的内容相同，都是StreamNode包含的operator的name(operatorName)。

如果要调大初始时候其他node的并行度，可以在这里操作：StreamGraphJSONGenerator#setInitParallelismAccordingToSource


StreamNode继续来包装SourceTransformation的相关信息，关键包括了：StreamOperator，jobVertexClass（AbstractInvokable类型的）。

用户编程时感知到的是各种Transformation，在get stream graph的时候，被transform 成StreamNode。


DataStreamSource 和 StreamSource 是完全不同的东西：

    DataStreamSource 前者继承自 SingleOutputStreamOperator<T> extends DataStream<T> ，是DataStream类型 
    (特别注意：SingleOutputStreamOperator的子类仅有 DataStreamSource 和 IterativeStream)，是datastream任务的开始点；
    
    StreamSource 后者是表示 stream 源头的 StreamOperator，是operator，不是DataStream类型。

类似的，需要注意 DataStreamSink 和 StreamSink 的区别。到了StreamNode这一层，operator就没有source/sink的区别了，它们就和其他operator一样的处理了。

